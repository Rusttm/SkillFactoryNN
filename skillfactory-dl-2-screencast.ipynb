{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wp8WHGm64-K_"
   },
   "source": [
    "# TF в Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gRO7QfGp4t-R"
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True  # более лучший автокомплит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rLn9z0wH4t-V",
    "outputId": "c02cf6e8-5556-4eb0-cce6-4fc674b92325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf \n",
    "import numpy as np\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "P4QBlx_l4t-Z",
    "outputId": "2bad5cd3-1e9f-4fc6-9e05-c4d294e6cab9"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.placeholder(tf.float32, (2, 2))\n",
    "b = tf.Variable(tf.ones((2, 2)))\n",
    "c = a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hUr9Z1wC4t-b",
    "outputId": "347c70cc-a25e-4f1b-dd0e-2eb0ec226890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"matmul:0\", shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "P23DN_wp_Efz",
    "outputId": "2585c54c-2b33-4e94-bfe1-fd2c08c174ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'Placeholder:0' shape=(2, 2) dtype=float32>, <tf.Tensor 'matmul/ReadVariableOp:0' shape=(2, 2) dtype=float32>]\n",
      "[<tf.Tensor 'matmul:0' shape=(2, 2) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(list(tf.get_default_graph().get_operations()[-1].inputs))\n",
    "print(list(tf.get_default_graph().get_operations()[-1].outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCpoFKcE4t-f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 21:59:29.723480: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-15 21:59:29.723890: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WLnkEvOD4t-j",
    "outputId": "59642ad9-9651-4a31-e601-04c9633107a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.run(tf.global_variables_initializer())\n",
    "s.run(c, feed_dict={a: np.ones((2, 2))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuK_53xo4t-m"
   },
   "outputs": [],
   "source": [
    "s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQSGgDQL4t-q"
   },
   "source": [
    "# Оптимизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VUtdayQ4t-q"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.get_variable(\"x\", shape=(), dtype=tf.float32, trainable=True)\n",
    "f = x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oO9CSWfr4t-t"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "step = optimizer.minimize(f, var_list=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KZOrrhyA4t-w",
    "outputId": "a22ba0c1-1127-4755-d752-8cbce875e8db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'x:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "gtNrbzDR4t-4",
    "outputId": "09bb9315-868b-43f0-b168-e4be5325219b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 21:59:44.361564: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-15 21:59:44.361618: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-02-15 21:59:44.366467: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-02-15 21:59:44.367879: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35074174 0.12301977\n",
      "0.2805934 0.078732654\n",
      "0.22447471 0.0503889\n",
      "0.17957976 0.032248892\n",
      "0.14366381 0.02063929\n",
      "0.11493105 0.0132091455\n",
      "0.091944836 0.0084538525\n",
      "0.07355587 0.0054104663\n",
      "0.058844697 0.0034626983\n",
      "0.047075756 0.0022161268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 21:59:44.608889: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:  # сессия сама закроется\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        _, curr_x, curr_f = s.run([step, x, f])\n",
    "        print(curr_x, curr_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fw_F68_34t_T"
   },
   "source": [
    "# TensorBoard логирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDAJKlYL4t_U"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.get_variable(\"x\", shape=(), dtype=tf.float32)\n",
    "f = x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OJ1n-qks4t_Z"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "step = optimizer.minimize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vemZEd5R4t_f"
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar('curr_x', x)\n",
    "tf.summary.scalar('curr_f', f)\n",
    "summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYPtORji4t_i"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 21:59:53.000331: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-15 21:59:53.000378: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-02-15 21:59:53.014377: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-15 21:59:53.028062: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:\n",
    "  summary_writer = tf.summary.FileWriter(\"logs/1\", s.graph)\n",
    "  s.run(tf.global_variables_initializer())\n",
    "  for i in range(10):\n",
    "      _, curr_summaries = s.run([step, summaries])\n",
    "      summary_writer.add_summary(curr_summaries, i)\n",
    "      summary_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxrA13Mm4t_m"
   },
   "source": [
    "Локально можно запустить  `tensorboard --logdir=./logs` в консоли.\n",
    "\n",
    "А вот так можно запустить прямо в Google Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SECWjGyg4t_m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port 6006 is closed, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: apt-get: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port 6006 is closed, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorBoard 2.6.0 at http://0.0.0.0:6006/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port 6006 is closed, retrying...\n",
      "Port 6006 is closed, retrying...\n",
      "Port 6006 is closed, retrying...\n",
      "Port 6006 is closed, retrying...\n",
      "Port 6006 is closed, retrying...\n",
      "Port 6006 is closed, retrying...\n",
      "Port 6006 is closed, retrying...\n",
      "Port 6006 is closed, retrying...\n",
      "Port 6006 is closed, retrying...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_q/03tkk3nx5xq63qd_bldrts5h0000gn/T/ipykernel_15241/3463477883.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# открываем порт из Google Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msetup_google_colab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpose_port_on_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6006\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/My Drive/Python/SkillFactoryNN/SkillFactoryNN/setup_google_colab.py\u001b[0m in \u001b[0;36mexpose_port_on_colab\u001b[0;34m(port)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\":{} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"netstat -vatn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Port {} is closed, retrying...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# run ngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/ZEMUSHKA/skillfactory-dl/master/setup_google_colab.py -O setup_google_colab.py -q\n",
    "import setup_google_colab\n",
    "\n",
    "# запускаем сервер tensorboard в фоне\n",
    "import os\n",
    "os.system(\"tensorboard --logdir=./logs --host 0.0.0.0 --port 6006 &\")\n",
    "\n",
    "# открываем порт из Google Colab\n",
    "setup_google_colab.expose_port_on_colab(6006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eNXcol8w4t_q"
   },
   "source": [
    "# Обучение линейной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_Z1KdRW14t_r",
    "outputId": "eb3c048e-f81d-4f70-8b24-52eccb7eb28c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3) (1000, 1)\n",
      "[[0.25447726 0.00566955 0.36972546]]\n"
     ]
    }
   ],
   "source": [
    "# модельные данные\n",
    "N = 1000\n",
    "D = 3\n",
    "x = np.random.random((N, D))\n",
    "w = np.random.random((D, 1))\n",
    "y = x @ w + np.random.randn(N, 1) * 0.20\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "print(w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HxC5KVBX4t_t",
    "outputId": "32988129-469f-4cd6-f659-4a5ace7d808e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1) (None, 1) ()\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "features = tf.placeholder(tf.float32, shape=(None, D), name=\"features\")\n",
    "target = tf.placeholder(tf.float32, shape=(None, 1), name=\"target\")\n",
    "\n",
    "weights = tf.get_variable(\"weights\", shape=(D, 1), dtype=tf.float32)\n",
    "predictions = features @ weights\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean((target - predictions) ** 2, name=\"loss\")\n",
    "\n",
    "print(target.shape, predictions.shape, loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kq76NAMF4t_7"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73GCLl0gHTLZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'features' type=Placeholder>,\n",
       " <tf.Operation 'target' type=Placeholder>,\n",
       " <tf.Operation 'weights/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'weights/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'weights/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'weights/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'weights/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'weights/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'weights/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'weights' type=VarHandleOp>,\n",
       " <tf.Operation 'weights/IsInitialized/VarIsInitializedOp' type=VarIsInitializedOp>,\n",
       " <tf.Operation 'weights/Assign' type=AssignVariableOp>,\n",
       " <tf.Operation 'weights/Read/ReadVariableOp' type=ReadVariableOp>,\n",
       " <tf.Operation 'matmul/ReadVariableOp' type=ReadVariableOp>,\n",
       " <tf.Operation 'matmul' type=MatMul>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'loss' type=Mean>,\n",
       " <tf.Operation 'gradients/Shape' type=Const>,\n",
       " <tf.Operation 'gradients/grad_ys_0/Const' type=Const>,\n",
       " <tf.Operation 'gradients/grad_ys_0' type=Fill>,\n",
       " <tf.Operation 'gradients/loss_grad/Reshape/shape' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/loss_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/loss_grad/Tile' type=Tile>,\n",
       " <tf.Operation 'gradients/loss_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/loss_grad/Shape_2' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Const' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Prod' type=Prod>,\n",
       " <tf.Operation 'gradients/loss_grad/Const_1' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Prod_1' type=Prod>,\n",
       " <tf.Operation 'gradients/loss_grad/Maximum/y' type=Const>,\n",
       " <tf.Operation 'gradients/loss_grad/Maximum' type=Maximum>,\n",
       " <tf.Operation 'gradients/loss_grad/floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'gradients/loss_grad/Cast' type=Cast>,\n",
       " <tf.Operation 'gradients/loss_grad/truediv' type=RealDiv>,\n",
       " <tf.Operation 'gradients/pow_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/pow_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/pow_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/pow_grad/mul' type=Mul>,\n",
       " <tf.Operation 'gradients/pow_grad/sub/y' type=Const>,\n",
       " <tf.Operation 'gradients/pow_grad/sub' type=Sub>,\n",
       " <tf.Operation 'gradients/pow_grad/Pow' type=Pow>,\n",
       " <tf.Operation 'gradients/pow_grad/mul_1' type=Mul>,\n",
       " <tf.Operation 'gradients/pow_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/pow_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/pow_grad/Greater/y' type=Const>,\n",
       " <tf.Operation 'gradients/pow_grad/Greater' type=Greater>,\n",
       " <tf.Operation 'gradients/pow_grad/ones_like/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/pow_grad/ones_like/Const' type=Const>,\n",
       " <tf.Operation 'gradients/pow_grad/ones_like' type=Fill>,\n",
       " <tf.Operation 'gradients/pow_grad/Select' type=Select>,\n",
       " <tf.Operation 'gradients/pow_grad/Log' type=Log>,\n",
       " <tf.Operation 'gradients/pow_grad/zeros_like' type=ZerosLike>,\n",
       " <tf.Operation 'gradients/pow_grad/Select_1' type=Select>,\n",
       " <tf.Operation 'gradients/pow_grad/mul_2' type=Mul>,\n",
       " <tf.Operation 'gradients/pow_grad/mul_3' type=Mul>,\n",
       " <tf.Operation 'gradients/pow_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/pow_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/pow_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/pow_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/pow_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/sub_grad/Shape' type=Shape>,\n",
       " <tf.Operation 'gradients/sub_grad/Shape_1' type=Shape>,\n",
       " <tf.Operation 'gradients/sub_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>,\n",
       " <tf.Operation 'gradients/sub_grad/Sum' type=Sum>,\n",
       " <tf.Operation 'gradients/sub_grad/Reshape' type=Reshape>,\n",
       " <tf.Operation 'gradients/sub_grad/Neg' type=Neg>,\n",
       " <tf.Operation 'gradients/sub_grad/Sum_1' type=Sum>,\n",
       " <tf.Operation 'gradients/sub_grad/Reshape_1' type=Reshape>,\n",
       " <tf.Operation 'gradients/sub_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/sub_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/sub_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'gradients/matmul_grad/MatMul' type=MatMul>,\n",
       " <tf.Operation 'gradients/matmul_grad/MatMul_1' type=MatMul>,\n",
       " <tf.Operation 'gradients/matmul_grad/tuple/group_deps' type=NoOp>,\n",
       " <tf.Operation 'gradients/matmul_grad/tuple/control_dependency' type=Identity>,\n",
       " <tf.Operation 'gradients/matmul_grad/tuple/control_dependency_1' type=Identity>,\n",
       " <tf.Operation 'GradientDescent/learning_rate' type=Const>,\n",
       " <tf.Operation 'GradientDescent/update_weights/ResourceApplyGradientDescent' type=ResourceApplyGradientDescent>,\n",
       " <tf.Operation 'GradientDescent' type=NoOp>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# производные это часть графа\n",
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "14EQwS8g4t_8",
    "outputId": "20bd6dd0-aa94-4b7d-95fe-b4ca7ba44492",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 22:00:59.573989: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-15 22:00:59.574063: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-02-15 22:00:59.579060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-15 22:00:59.624827: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.116178855\n",
      "0.052195497\n",
      "0.041217502\n",
      "0.03926909\n",
      "0.03891988\n",
      "0.038856618\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    for i in range(300):\n",
    "        _, curr_loss, curr_weights = s.run([step, loss, weights], \n",
    "                                           feed_dict={features: x, target: y})\n",
    "        if i % 50 == 0:\n",
    "            print(curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Le4UwJw14uAA",
    "outputId": "712fac2c-3bde-49ce-c289-a9e223f6bd8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25537354, -0.03024207,  0.38736644]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# результат обучения\n",
    "curr_weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8cqImP2P4uAF",
    "outputId": "bd9d7ad3-8b42-4edd-85b2-a4d5041cdf66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25447726, 0.00566955, 0.36972546]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# правильные веса\n",
    "w.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yvG2r5miBCLF"
   },
   "source": [
    "# Обучение в Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p0c0fnlpBGCI",
    "outputId": "b140349b-867d-4aca-fc3d-ed1a19b1a572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.models as M\n",
    "import keras.layers as L\n",
    "import keras.backend as K\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "egw2cWPnBab3",
    "outputId": "a558dc1a-20de-4835-aba0-7b67e5824dd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()  # очищает граф и перезапускает сессию\n",
    "\n",
    "model = M.Sequential()\n",
    "model.add(L.Dense(1, use_bias=False, input_shape=(D,)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65R7pZxJCCj9"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "6dykIkErCbQN",
    "outputId": "f5f6396e-a100-41b2-d815-a8ca8c547287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 22:01:10.968260: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-15 22:01:10.968289: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-02-15 22:01:10.973133: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-15 22:01:10.978163: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-15 22:01:10.988571: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-15 22:01:10.992337: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 568/1000 [================>.............] - ETA: 0s - loss: 0.3030 - mse: 0.3030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 22:01:11.357306: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-02-15 22:01:11.357314: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-02-15 22:01:11.360348: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-02-15 22:01:11.363994: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-02-15 22:01:11.368498: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/keras/plugins/profile/2022_02_15_22_01_11\n",
      "2022-02-15 22:01:11.369422: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/keras/plugins/profile/2022_02_15_22_01_11/Johns-MacBook-Pro.local.trace.json.gz\n",
      "2022-02-15 22:01:11.372239: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/keras/plugins/profile/2022_02_15_22_01_11\n",
      "2022-02-15 22:01:11.372478: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/keras/plugins/profile/2022_02_15_22_01_11/Johns-MacBook-Pro.local.memory_profile.json.gz\n",
      "2022-02-15 22:01:11.372770: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/keras/plugins/profile/2022_02_15_22_01_11Dumped tool data for xplane.pb to ./logs/keras/plugins/profile/2022_02_15_22_01_11/Johns-MacBook-Pro.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/keras/plugins/profile/2022_02_15_22_01_11/Johns-MacBook-Pro.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/keras/plugins/profile/2022_02_15_22_01_11/Johns-MacBook-Pro.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/keras/plugins/profile/2022_02_15_22_01_11/Johns-MacBook-Pro.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/keras/plugins/profile/2022_02_15_22_01_11/Johns-MacBook-Pro.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 624us/sample - loss: 0.2515 - mse: 0.2515\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 243us/sample - loss: 0.1357 - mse: 0.1357\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 247us/sample - loss: 0.1039 - mse: 0.1039\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 246us/sample - loss: 0.0831 - mse: 0.0831\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 243us/sample - loss: 0.0689 - mse: 0.0689\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 242us/sample - loss: 0.0593 - mse: 0.0593\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 233us/sample - loss: 0.0527 - mse: 0.0527\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 238us/sample - loss: 0.0483 - mse: 0.0483\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 260us/sample - loss: 0.0453 - mse: 0.0453\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 245us/sample - loss: 0.0432 - mse: 0.0432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286e61100>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=8, epochs=10, callbacks=[keras.callbacks.TensorBoard(\"./logs/keras\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "aUS7jvpWCpmY",
    "outputId": "66a7a84f-6e74-40c8-9391-d4fa45a2a58a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 22:01:16.208745: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.29914093],\n",
       "        [0.09611366],\n",
       "        [0.21689846]], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = K.get_session()\n",
    "s.run(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "skillfactory-2-screencast.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
